{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use [mongoDB](http://www.mongodb.org/) along with [Pymongo](http://api.mongodb.org/python/current/) for personal projects only (I hope this changes in the near future though) and not very often to be honest. So this post is more of a quick reference for myself and I hope you guys finds it useful too. I am also writing this post in [Ipython](http://ipython.org/) which I will convert to [markdown](http://en.wikipedia.org/wiki/Markdown) using [nbconvert utility](http://blog.fperez.org/2012/09/blogging-with-ipython-notebook.html) and then push it to my github blog using [Jekyll](http://jekyllbootstrap.com/). Fingers crossed it won't be too difficult.\n",
    "\n",
    "For this tutorial I'll be using real data from Twitter using the [Tweepy](https://github.com/tweepy/tweepy) package.\n",
    "\n",
    "Before we start let's see what Wikipedia has to say about MongoDB:\n",
    "\n",
    "> \"MongoDB (from \"humongous\") is an open source document-oriented database system developed and supported by 10gen. It is part of the NoSQL family of database systems. Instead of storing data in tables as is done in a \"classical\" relational database, MongoDB stores structured data as JSON-like documents with dynamic schemas (MongoDB calls the format BSON), making the integration of data in certain types of applications easier and faster.\n",
    "\n",
    ">10gen began Development of MongoDB in October 2007. The database is used by MTV Networks, Craigslist, Foursquare and UIDAI Aadhaar. MongoDB is the most popular NoSQL database management system.\"\n",
    "\n",
    "Done - let's start!\n",
    "\n",
    "## Downloading & Installing MongoDB binaries\n",
    "\n",
    "1. Head to the MongoDB download page [http://www.mongodb.org/downloads](http://www.mongodb.org/downloads) and get version 2.2.2 (or latest stable version) for your OS (*by the way I'm using OSX for this tutorial so \\*nix guys should have no difficulty following along but Windows users may need to change some bits - sorry!*).\n",
    "\n",
    "2. Unzip mongodb-osx-x86_64-2.2.2.tgz and rename folder mongodb-osx-x86_64-2.2.2 to simply mongodb. I normally move this folder to my personal project folder so feel free to move it in wherever you like. Your mongodb folder should have the following structure: \n",
    "`\n",
    "altons@asgard:~/projects$ls -R mongodb\n",
    "GNU-AGPL-3.0        README              THIRD-PARTY-NOTICES bin\n",
    "mongodb/bin:\n",
    "bsondump     mongod       mongoexport  mongoimport  mongoperf    mongos       mongostat\n",
    "mongo        mongodump    mongofiles   mongooplog   mongorestore mongosniff   mongotop\n",
    "altons@asgard:~/projects$\n",
    "`\n",
    "3. Kick off the mongodb server:\n",
    "`\n",
    "altons@asgard:~/projects$ cd mongodb\n",
    "altons@asgard:~/projects/mongodb$./bin/mongod --dbpath . --nojournal &\n",
    "`\n",
    "4. Open another terminal windows and type: `altons@asgard:~/projects/mongodb$./bin/mongo`\n",
    "\n",
    "if you something like:\n",
    "`\n",
    "MongoDB shell version: 2.2.2\n",
    "connecting to: test\n",
    "Welcome to the MongoDB shell.\n",
    "For interactive help, type \"help\".\n",
    "For more comprehensive documentation, see\n",
    "\thttp://docs.mongodb.org/\n",
    "Questions? Try the support group\n",
    "\thttp://groups.google.com/group/mongodb-user\n",
    "> \n",
    "`\n",
    "then you are good to go! Type **exit** to quit and go to the previous terminal windows and hit Ctrl+C to kill the server  - we need a bit of customization first.\n",
    "\n",
    "**Note**: Sometimes (with God as my witness!) Ctrl-C doesn't kill the server and I have to do a `kill -9` on the pid where mongod still running. If that happens - you also need to remove mongodb.lock from your **dbpath** manually otherwise mongoDB will complain next time you fire it up.\n",
    "\n",
    "## The config file\n",
    "\n",
    "The option --dbpath . will save your data inside the mongodb folder - I am not a huge fan of this option. I like to keep my data separated from db binaries. So instead I'll use a config file to tell mongoDB where to store my data.\n",
    "\n",
    "Here it is my config file:\n",
    "`\n",
    "# Mongo Production server configuration\n",
    "# Author: Alberto Negron\n",
    "# created on: 26/07/2012\n",
    "\n",
    "dbpath=/Users/altons/projects/data/mongodb/                         # location where I want to store my databases - Use full path\n",
    "port = 27017                                                        # default port\n",
    "bind_ip = 127.0.0.1                                                 # default ip\n",
    "logpath = /Users/altons/projects/data/mongodb/log/mongodb.log       # location where I want to store logs - Use full path\n",
    "logappend = true                                                    # everytime I fire up mongodb the new log will be appended to a master log file\n",
    "rest=true                                                           # this option let you check server status at http:\\\\127.0.0.1:27017\n",
    "directoryperdb = true                                               # Set to true to modify the storage pattern of the data directory to store each database’s\n",
    "                                                                    # files in a distinct folder. This option will create directories within the dbpath \n",
    "                                                                    # named for each directory\n",
    "\n",
    "`\n",
    "and I have saved it as mongo.conf in side the data folder ` (~/projects/data) `.\n",
    "\n",
    "Now go back to the mongodb folder and use the following command to fire up the server:\n",
    "\n",
    "`\n",
    "altons@asgard:~/projects/mongodb$./bin/mongod --config=/Users/altons/projects/data/mongo.conf  --nojournal &\n",
    "`\n",
    "\n",
    "Since the option rest is set to true you can check mongodb status via [http://127.0.0.1:28017/](http://127.0.0.1:28017/)\n",
    "\n",
    "You can have  multiple config files (Prod/Dev/Test) or any combination of servers running on different ports. Options are endless.\n",
    "\n",
    "## Pymongo\n",
    "\n",
    "PyMongo is a Python distribution containing tools for working with MongoDB, and is the recommended way to work with MongoDB from Python. You can install mongodb from either pip or easy_install.\n",
    "\n",
    "### Connecting to MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pymongo 2.4.1 the connection method has been deprecated. Now we most use MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MongoClient('localhost', 27017)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connection to Mongo DB\n",
    "try:\n",
    "    conn=pymongo.MongoClient()\n",
    "    print \"Connected successfully!!!\"\n",
    "except pymongo.errors.ConnectionFailure, e:\n",
    "   print \"Could not connect to MongoDB: %s\" % e \n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now connected to our server.\n",
    "\n",
    "### Databases\n",
    "\n",
    "Mongodb creates databases and collections automatically for you if they don't exist already. A single instance of MongoDB can support multiple independent databases. When working with PyMongo you access databases using attribute style access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient('localhost', 27017), u'mydb')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = conn.mydb\n",
    "db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your database name is such that using attribute style access won’t work (like db-name), you can use dictionary style access instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient('localhost', 27017), u'sandpit-test')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = conn['sandpit-test']\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to know what databases are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sample', u'local', u'pcat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already created 2 new databases. Why didn't show up with the above command? Well, databases with no collections or with empty collections will not show up with database_names(). Same goes when we try to list empty collections in a database.\n",
    "\n",
    "We'll test it again once we have populate some collections.\n",
    "\n",
    "### Collections\n",
    "\n",
    "A collection is a group of documents stored in MongoDB, and can be thought of as roughly the equivalent of a table in a relational database. Getting a collection in PyMongo works the same as getting a database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient('localhost', 27017), u'sandpit-test'), u'my_collection')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.my_collection\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However one must be careful when trying to get existing collections. For example, if you a collection db.user and you type db.usr this is clearly a typo. Unlike an RDBMS, MongoDB won't protect you from this class of mistake.\n",
    "\n",
    "\n",
    "### Documents\n",
    "\n",
    "MongoDB stores structured data as JSON-like documents, using dynamic schemas (called BSON), rather than predefined schemas. An element of data is called a document, and documents are stored in collections. One collection may have any number of documents.\n",
    "\n",
    "Compared to relational databases, we could say collections are like tables, and documents are like records. But there is one big difference: every record in a table has the same fields (with, usually, differing values) in the same order, while each document in a collection can have completely different fields from the other documents. \n",
    "\n",
    "All you really need to know when you're using Python, however, is that documents are Python dictionaries that can have strings as keys and can contain various primitive types (int, float,unicode, datetime) as well as other documents (Python dicts) and arrays (Python lists).\n",
    "\n",
    "To insert some data into MongoDB, all we need to do is create a dict and call .insert() on the collection object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = {\"name\":\"Alberto\",\"surname\":\"Negron\",\"twitter\":\"@Altons\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to insert the above document into a collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('562402c8801d32092c116566')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations you have created your first document!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sample', u'local', u'sandpit-test', u'pcat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'my_collection', u'system.indexes']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now database_names() and collection_names() show database **sandpit-test** and collection **my_collection**.\n",
    "\n",
    "To recap, we have **databases** containing **collections**. A **collection** is made up of **documents**. Each document is made up of **fields**.\n",
    "\n",
    "\n",
    "## Tweepy\n",
    "\n",
    "Before continue with the tutorial, let's get some real data from twitter and insert it in a new database - it'll be definitely more interesting!!!\n",
    "\n",
    "Let's pull the first 10 result pages with the keyword 'BigData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup ='BigData'\n",
    "api = API()\n",
    "\n",
    "search = []\n",
    "page = 1\n",
    "maxPage = 10\n",
    "while(page<=maxPage):\n",
    "    tweets = api.search(lookup,page = page)\n",
    "    for tweet in tweets:\n",
    "        search.append(tweet)\n",
    "    page = page + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's how many tweets we got from the above search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, let inspect the structure of the first object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_api',\n",
       " 'created_at',\n",
       " 'from_user',\n",
       " 'from_user_id',\n",
       " 'from_user_id_str',\n",
       " 'from_user_name',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'iso_language_code',\n",
       " 'metadata',\n",
       " 'parse',\n",
       " 'parse_list',\n",
       " 'profile_image_url',\n",
       " 'profile_image_url_https',\n",
       " 'source',\n",
       " 'text',\n",
       " 'to_user',\n",
       " 'to_user_id',\n",
       " 'to_user_id_str',\n",
       " 'to_user_name']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(search[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information that we really don't need. Let's keep only the data related to the tweet and insert it into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define my mongoDB database\n",
    "db = conn.twitter_results\n",
    "# Define my collection where I'll insert my search\n",
    "posts = db.posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loop through search and insert dictionary into mongoDB\n",
    "for tweet in search:\n",
    "    # Empty dictionary for storing tweet related data\n",
    "    data ={}\n",
    "    data['created_at'] = tweet.created_at\n",
    "    data['from_user'] = tweet.from_user\n",
    "    data['from_user_id'] = tweet.from_user_id\n",
    "    data['from_user_id_str'] = tweet.from_user_id_str\n",
    "    data['from_user_name'] = tweet.from_user_name\n",
    "    data['geo'] = tweet.geo\n",
    "    data['id'] = tweet.id\n",
    "    data['iso_language_code'] = tweet.iso_language_code\n",
    "    data['source'] = tweet.source\n",
    "    data['text'] = tweet.text\n",
    "    data['to_user'] = tweet.to_user\n",
    "    data['to_user_id'] = tweet.to_user_id\n",
    "    data['to_user_id_str'] = tweet.to_user_id_str\n",
    "    data['to_user_name'] = tweet.to_user_name\n",
    "    # Insert process\n",
    "    posts.insert(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dead easy! we have created our collection of tweets, no need to define table and columns beforehand - that's the beauty of MongoDB.\n",
    "\n",
    "Here it is the structure of the last document inserted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('50f99bf66577e466cf550bc8'),\n",
       " 'created_at': datetime.datetime(2013, 1, 18, 18, 1, 38),\n",
       " 'from_user': u'Adriana_iSchool',\n",
       " 'from_user_id': 303810955,\n",
       " 'from_user_id_str': u'303810955',\n",
       " 'from_user_name': u'Adriana Rossini',\n",
       " 'geo': None,\n",
       " 'id': 292330927105916928L,\n",
       " 'iso_language_code': u'en',\n",
       " 'source': u'Twuffer',\n",
       " 'text': u'New big data firm to pioneer topological data analysis http://t.co/uEHYdcnM via @guardian #BigData #topology',\n",
       " 'to_user': None,\n",
       " 'to_user_id': 0,\n",
       " 'to_user_id_str': u'0',\n",
       " 'to_user_name': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The _id field\n",
    "\n",
    "\n",
    "In MongoDB, documents stored in a collection require a unique _id field that acts as a primary key. Because ObjectIds are small, most likely unique, and fast to generate, MongoDB uses ObjectIds as the default value for the _id field if the _id field is not specified; i.e., the mongod adds the _id field and generates a unique ObjectId to assign as its value\n",
    "\n",
    "## Reading Documents in a Collection\n",
    "\n",
    "The first and foremost important operation we need to learn is how to retrieve our data from MongoDB. For this, Collections provide the find_one() and find() methods:\n",
    "\n",
    "- The find_one() method selects and returns a single document from a collection and returns that document (or None if there are no matches). It is useful when you know there is only one matching document, or are only interested in the first match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('50f99bf66577e466cf550b34'),\n",
       " u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1),\n",
       " u'from_user': u'BITechWatch',\n",
       " u'from_user_id': 22631958,\n",
       " u'from_user_id_str': u'22631958',\n",
       " u'from_user_name': u'Marly Cho',\n",
       " u'geo': None,\n",
       " u'id': 292341338840653825L,\n",
       " u'iso_language_code': u'en',\n",
       " u'source': u'twitterfeed',\n",
       " u'text': u\"Everything you ever wanted to know about R functions: It's hard to overstate the importance of function... http://t.co/sD5bG4yg #bigdata\",\n",
       " u'to_user': None,\n",
       " u'to_user_id': 0,\n",
       " u'to_user_id_str': u'0',\n",
       " u'to_user_name': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get more than a single document as the result of a query we use the find() method. find() returns a Cursor instance, which allows us to iterate over all matching documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posts.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can iterate over the first 2 documents (there are a lot in the collection and this is just an example) in the posts collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'iso_language_code': u'en', u'to_user_name': None, u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1), u'text': u\"Everything you ever wanted to know about R functions: It's hard to overstate the importance of function... http://t.co/sD5bG4yg #bigdata\", u'from_user_id_str': u'22631958', u'to_user_id_str': u'0', u'to_user': None, u'source': u'twitterfeed', u'to_user_id': 0, u'from_user': u'BITechWatch', u'id': 292341338840653825L, u'from_user_id': 22631958, u'_id': ObjectId('50f99bf66577e466cf550b34'), u'geo': None, u'from_user_name': u'Marly Cho'}\n",
      "{u'iso_language_code': u'en', u'to_user_name': None, u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1), u'text': u'RT @IBMcloud: Big data in the #cloud? Governing a sprawling business resource http://t.co/FDsoNfrf via @jameskobielus #bigdata', u'from_user_id_str': u'115674359', u'to_user_id_str': u'0', u'to_user': None, u'source': u'web', u'to_user_id': 0, u'from_user': u'ibmmb', u'id': 292341338798690304L, u'from_user_id': 115674359, u'_id': ObjectId('50f99bf66577e466cf550b35'), u'geo': None, u'from_user_name': u'Maarten Boerma'}\n"
     ]
    }
   ],
   "source": [
    "for d in posts.find()[:2]:\n",
    "    print d\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also use the standard python list():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('50f99bf66577e466cf550b34'),\n",
       "  u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1),\n",
       "  u'from_user': u'BITechWatch',\n",
       "  u'from_user_id': 22631958,\n",
       "  u'from_user_id_str': u'22631958',\n",
       "  u'from_user_name': u'Marly Cho',\n",
       "  u'geo': None,\n",
       "  u'id': 292341338840653825L,\n",
       "  u'iso_language_code': u'en',\n",
       "  u'source': u'twitterfeed',\n",
       "  u'text': u\"Everything you ever wanted to know about R functions: It's hard to overstate the importance of function... http://t.co/sD5bG4yg #bigdata\",\n",
       "  u'to_user': None,\n",
       "  u'to_user_id': 0,\n",
       "  u'to_user_id_str': u'0',\n",
       "  u'to_user_name': None},\n",
       " {u'_id': ObjectId('50f99bf66577e466cf550b35'),\n",
       "  u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1),\n",
       "  u'from_user': u'ibmmb',\n",
       "  u'from_user_id': 115674359,\n",
       "  u'from_user_id_str': u'115674359',\n",
       "  u'from_user_name': u'Maarten Boerma',\n",
       "  u'geo': None,\n",
       "  u'id': 292341338798690304L,\n",
       "  u'iso_language_code': u'en',\n",
       "  u'source': u'web',\n",
       "  u'text': u'RT @IBMcloud: Big data in the #cloud? Governing a sprawling business resource http://t.co/FDsoNfrf via @jameskobielus #bigdata',\n",
       "  u'to_user': None,\n",
       "  u'to_user_id': 0,\n",
       "  u'to_user_id_str': u'0',\n",
       "  u'to_user_name': None}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(posts.find())[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "If we just want to know how many documents match a query we can perform a count() operation instead of a full query. We can get a count of all of the documents in a collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Operators\n",
    "\n",
    "MongoDB queries are represented as JSON-like structure, just like documents. To build a query, you just need to specify a dictionary with the properties you wish the results to match. For example, this query will match all documents in the posts collection with ISO language code \"en\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find({\"iso_language_code\": \"en\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to retrieve all documents with ISO language code \"en\" and source equal to \"twitterfeed\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find({\"iso_language_code\":\"en\",\"source\":\"twitterfeed\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries can also use special query operators. These operators include **gt, gte, lt, lte, ne, nin, regex, exists, not, or**, and many more. The following queries show the use of some of these operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('50f99bf66577e466cf550b34'),\n",
       " u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1),\n",
       " u'from_user': u'BITechWatch',\n",
       " u'from_user_id': 22631958,\n",
       " u'from_user_id_str': u'22631958',\n",
       " u'from_user_name': u'Marly Cho',\n",
       " u'geo': None,\n",
       " u'id': 292341338840653825L,\n",
       " u'iso_language_code': u'en',\n",
       " u'source': u'twitterfeed',\n",
       " u'text': u\"Everything you ever wanted to know about R functions: It's hard to overstate the importance of function... http://t.co/sD5bG4yg #bigdata\",\n",
       " u'to_user': None,\n",
       " u'to_user_id': 0,\n",
       " u'to_user_id_str': u'0',\n",
       " u'to_user_name': None}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# cheat: year, month, day, hour, minute, second, microsecond\n",
    "date1 = datetime.strptime(\"18/01/13 18:30\", \"%d/%m/%y %H:%M\")\n",
    "date2 = datetime.strptime(\"18/01/13 18:05\", \"%d/%m/%y %H:%M\")\n",
    "date3 = datetime.strptime(\"18/01/13 18:10\", \"%d/%m/%y %H:%M\")\n",
    "date4 = datetime.strptime(\"18/01/13 18:25\", \"%d/%m/%y %H:%M\")\n",
    "\n",
    "cursor = posts.find({'created_at':{\"$gt\":date1}})\n",
    "cursor.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will do the same query but add the count() method to only get the count of documents that match the query. We will use count() from now onwards (easier!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find({'created_at':{\"$gt\":date1}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets dates low than or equal to date2\n",
    "posts.find({'created_at':{\"$lte\":date2}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Between 2 dates\n",
    "posts.find({\"created_at\": {\"$gte\": date3, \"$lt\": date4}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Posts in either spanish or french\n",
    "posts.find({\"iso_language_code\":{\"$in\":[\"es\",\"fr\"]}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Posts in either spanish or french using $or\n",
    "posts.find({\"$or\":[{\"iso_language_code\":\"es\"},{\"iso_language_code\":\"fr\"}]}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All posts except spanish or french\n",
    "posts.find({\"iso_language_code\":{\"$nin\":[\"es\",\"fr\"]}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('50f99bf66577e466cf550b3b'),\n",
       " u'created_at': datetime.datetime(2013, 1, 18, 18, 41, 23),\n",
       " u'from_user': u'DGleebits',\n",
       " u'from_user_id': 364557525,\n",
       " u'from_user_id_str': u'364557525',\n",
       " u'from_user_name': u'Dan Gleebits ',\n",
       " u'geo': None,\n",
       " u'id': 292340928268623872L,\n",
       " u'iso_language_code': u'en',\n",
       " u'source': u'Tweet Button',\n",
       " u'text': u'LazyWeb Reblog of Big Data Security Challenges http://t.co/vAY5CVOz via @wordpressdotcom #infosec #dfir #bigdata #analytics',\n",
       " u'to_user': None,\n",
       " u'to_user_id': 0,\n",
       " u'to_user_id_str': u'0',\n",
       " u'to_user_name': None}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Regex to find a post with hashtag #analytics\n",
    "import re\n",
    "regex = re.compile(r'#analytics')\n",
    "rstats = posts.find_one({\"text\":regex})\n",
    "rstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll cover other operators further down once we have covered the Update process.\n",
    "\n",
    "## Sorting Documents\n",
    "\n",
    "MongoDB can sort query results for you on the server-side. Especially if you are sorting results on a property which has an index, it can sort these far more efficiently than your client program can.\n",
    "\n",
    "Here's an exmaple of using a descending sort to get the last tweet in our collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('50f99bf66577e466cf550b34'),\n",
       " u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1),\n",
       " u'from_user': u'BITechWatch',\n",
       " u'from_user_id': 22631958,\n",
       " u'from_user_id_str': u'22631958',\n",
       " u'from_user_name': u'Marly Cho',\n",
       " u'geo': None,\n",
       " u'id': 292341338840653825L,\n",
       " u'iso_language_code': u'en',\n",
       " u'source': u'twitterfeed',\n",
       " u'text': u\"Everything you ever wanted to know about R functions: It's hard to overstate the importance of function... http://t.co/sD5bG4yg #bigdata\",\n",
       " u'to_user': None,\n",
       " u'to_user_id': 0,\n",
       " u'to_user_id_str': u'0',\n",
       " u'to_user_name': None}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastTweet = posts.find().sort([(\"created_at\", pymongo.DESCENDING)])\n",
    "lastTweet.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the first tweet in french?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('50f99bf66577e466cf550b99'),\n",
       " u'created_at': datetime.datetime(2013, 1, 18, 18, 13, 52),\n",
       " u'from_user': u'jbmgrtn',\n",
       " u'from_user_id': 87185256,\n",
       " u'from_user_id_str': u'87185256',\n",
       " u'from_user_name': u'J\\xe9r\\xf4me Baumgarten',\n",
       " u'geo': None,\n",
       " u'id': 292334004466761729L,\n",
       " u'iso_language_code': u'fr',\n",
       " u'source': u'Twitter for iPhone',\n",
       " u'text': u'@jhattat la pr\\xe9s dont je parlais sur BigData et Hadoop http://t.co/4McdjN80',\n",
       " u'to_user': u'jhattat',\n",
       " u'to_user_id': 24175910,\n",
       " u'to_user_id_str': u'24175910',\n",
       " u'to_user_name': u'J\\xe9r\\xe9mie HATTAT'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frlastTweet = posts.find({\"iso_language_code\":\"fr\"}).sort([(\"created_at\", pymongo.ASCENDING)])\n",
    "frlastTweet.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above queries are not very optimal when you have large result sets. Pymongo have a limit() method which let you fetch a limited number of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'iso_language_code': u'en', u'to_user_name': None, u'created_at': datetime.datetime(2013, 1, 18, 18, 43, 1), u'text': u\"Everything you ever wanted to know about R functions: It's hard to overstate the importance of function... http://t.co/sD5bG4yg #bigdata\", u'from_user_id_str': u'22631958', u'to_user_id_str': u'0', u'to_user': None, u'source': u'twitterfeed', u'to_user_id': 0, u'from_user': u'BITechWatch', u'id': 292341338840653825L, u'from_user_id': 22631958, u'_id': ObjectId('50f99bf66577e466cf550b34'), u'geo': None, u'from_user_name': u'Marly Cho'}\n"
     ]
    }
   ],
   "source": [
    "lastTweetOnly = posts.find().sort([(\"created_at\", pymongo.DESCENDING)]).limit(1)\n",
    "for t in lastTweetOnly: print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Documents\n",
    "\n",
    "PyMongo can update documents in a number of different ways. Let's start for adding a new document to our collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.insert({\"_id\":1234,\"created_at\":datetime(2013,1,21,15,27,59),\"text\":\"Hello World\", \"from_user\":\"Altons\",\"source\":\"Ipython\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'created_at': datetime.datetime(2013, 1, 21, 15, 27, 59),\n",
       " u'from_user': u'Altons',\n",
       " u'source': u'Ipython',\n",
       " u'text': u'Hello World'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the update() method to modify the document. This operation finds the document we just inserted by _id and updates it with a new document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234, u'from_user': u'anonymous'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"from_user\":\"anonymous\"})\n",
    "\n",
    "#Fetch our updated document\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update() method replaces the whole document so be careful! If instead we want to modify specific fields of the document we can use MongoDB's update operators like **set, inc, push, pull** and many more.\n",
    "\n",
    "### Update Operator: set\n",
    "\n",
    "This statement updates in the document in collection where field matches value1 by replacing the value of the field field1 with value2. This operator will add the specified field or fields if they do not exist in this document or replace the existing value of the specified field(s) if they already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234, u'from_user': u'Altons', u'source': u'Ipython notebook'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$set\":{\"from_user\":\"Altons\",\"source\":\"Ipython notebook\"}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsert**\n",
    "\n",
    "An **upsert** eliminates the need to perform a separate database call to check for the existence of a record before performing either an update or an insert operation. Typically update operations update existing documents, but in MongoDB, the update() operation can accept an **upsert** option as an argument. Upserts are a hybrid operation that use the **query** argument to determine the write operation:\n",
    "\n",
    "- If the query matches an existing document(s), the upsert performs an update.\n",
    "- If the query matches no document in the collection, the upsert inserts a single document.\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":5678},{\"$set\":{\"from_user\":\"Alberto\",\"source\":\"unavailable\"}})\n",
    "posts.find({\"_id\":5678}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update fails because no document matched the query for the update. But using upsert will sort this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":5678},{\"$set\":{\"from_user\":\"Alberto\",\"source\":\"unavailable\"}}, upsert=True)\n",
    "posts.find({\"_id\":5678}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multi=True**\n",
    "\n",
    "By default MongoDB only modifies the first document that matches the query. If you want to modify all documents that match the query add multi=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operator: inc\n",
    "\n",
    "The inc operator increments a value by a specified amount if field is present in the document. If the field does not exist, $inc sets field to the number value. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'from_user': u'Altons',\n",
       " u'source': u'Ipython notebook',\n",
       " u'total_posts': 1}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$set\":{\"total_posts\":1}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'from_user': u'Altons',\n",
       " u'source': u'Ipython notebook',\n",
       " u'total_posts': 10}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increment total_posts by 9 tweets\n",
    "posts.update({\"_id\":1234},{\"$inc\":{\"total_posts\":9}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Update Operator: unset\n",
    "\n",
    "The unset operator deletes a particular field. If documents match the initial query but do not have the field specified in the unset operation, there the statement has no effect on the document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234, u'from_user': u'Altons', u'source': u'Ipython notebook'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$unset\":{\"total_posts\":\"\"}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operator: rename\n",
    "\n",
    "The rename operator updates the name of a field. The new field name must differ from the existing field name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234, u'source': u'Ipython notebook', u'username': u'Altons'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$rename\":{\"from_user\":\"username\"}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a good opportunity to see **exists** in action (it should return only 1 as there only one document with field **username**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find({\"username\":{\"$exists\":True}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operator: push \n",
    "\n",
    "The **push** operator appends a specified value to an array.Be aware of the following behaviors:\n",
    "\n",
    "- If the field specified in the **push** statement (e.g. { $push: { field: value1 } }) does not exist in the matched document, the operation adds a new array with the specified field and value (e.g. value1) to the matched document.\n",
    "- The operation will fail if the field specified in the **push** statement is not an array. $push does not fail when pushing a value to a non-existent field.\n",
    "- If value1 is an array itself, **push** appends the whole array as an element in the identified array. To add multiple items to an array, use [pushAll](http://docs.mongodb.org/manual/reference/operator/pushAll/#_S_pushAll).\n",
    "\n",
    "Now for this example, let's say we have 2 predictive models that score the sentiment of each tweet in the range -5,5 (-5 = worse, 0 = neutral and 5=best) and we want to add those scores to each document.\n",
    "\n",
    "Let's use our well known document _id=1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': 0, u'svm': -2}],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "posts.update({\"_id\":1234},{\"$push\":{\"sentiment\":{\"nb\":random.randint(-5, 5),\"svm\":random.randint(-5, 5)}}})\n",
    "posts.find_one({\"_id\":1234})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we have added scores to document 1234, let's see what happens if we run the same code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': 0, u'svm': -2}, {u'nb': 1, u'svm': 4}],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$push\":{\"sentiment\":{\"nb\":random.randint(-5, 5),\"svm\":random.randint(-5, 5)}}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it will add another array as expected. I don't know why one would think it will update the original array instead of appending a new one. So don't make the mistake I did!\n",
    "\n",
    "if you run it twice or more you always have the **unset** operator to the rescue (if you want to start from scratch!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234, u'source': u'Ipython notebook', u'username': u'Altons'}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$unset\":{\"sentiment\":\"\"}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operator: pop\n",
    "\n",
    "The **pop** operator removes the first or last element of an array. Pass **pop** a value of 1 to remove the last element in an array and a value of -1 to remove the first element of an array.\n",
    "\n",
    "Be aware of the following **pop** behaviors:\n",
    "\n",
    "- The **pop** operation fails if field is not an array.\n",
    "- **pop** will successfully remove the last item in an array. field will then hold an empty array.\n",
    "\n",
    "We can use **pop** if we don't want to start (or can't) from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': -5, u'svm': 0}, {u'nb': 4, u'svm': 2}],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$push\":{\"sentiment\":{\"nb\":random.randint(-5, 5),\"svm\":random.randint(-5, 5)}}})\n",
    "posts.update({\"_id\":1234},{\"$push\":{\"sentiment\":{\"nb\":random.randint(-5, 5),\"svm\":random.randint(-5, 5)}}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': -5, u'svm': 0}],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":1234},{\"$pop\":{\"sentiment\":1}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operator: pull\n",
    "\n",
    "The **pull** operator removes all instances of a value from an existing array. If the value existed multiple times in the field array, **pull** would remove all instances of this value in this array.\n",
    "\n",
    "It is very handy when you exactly what value you want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 5678,\n",
       " u'from_user': u'Alberto',\n",
       " u'skills': [u'python', u'SAS', u'R', u'javascript', u'java'],\n",
       " u'source': u'unavailable'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":5678},{\"$set\":{\"skills\":[\"python\",\"SAS\",\"R\",\"javascript\",\"java\"]}})\n",
    "posts.find_one({\"_id\":5678})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 5678,\n",
       " u'from_user': u'Alberto',\n",
       " u'skills': [u'python', u'SAS', u'R', u'javascript'],\n",
       " u'source': u'unavailable'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":5678},{\"$pull\":{\"skills\":\"java\"}})\n",
    "posts.find_one({\"_id\":5678})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operator: addToSet\n",
    "\n",
    "The **addToSet** operator adds a value to an array only if the value is not in the array already. If the value is in the array, **addToSet** returns without modifying the array. Otherwise, **addToSet** behaves the same as **push**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 5678,\n",
       " u'from_user': u'Alberto',\n",
       " u'skills': [u'python', u'SAS', u'R', u'javascript'],\n",
       " u'source': u'unavailable'}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find_one({\"_id\":5678})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 5678,\n",
       " u'from_user': u'Alberto',\n",
       " u'skills': [u'python', u'SAS', u'R', u'javascript'],\n",
       " u'source': u'unavailable'}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":5678},{\"$addToSet\":{\"skills\":\"python\"}})\n",
    "posts.find_one({\"_id\":5678})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 5678,\n",
       " u'from_user': u'Alberto',\n",
       " u'skills': [u'python', u'SAS', u'R', u'javascript', u'Perl'],\n",
       " u'source': u'unavailable'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.update({\"_id\":5678},{\"$addToSet\":{\"skills\":\"Perl\"}})\n",
    "posts.find_one({\"_id\":5678})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Update Operator: $\n",
    "\n",
    "The positional $ operator identifies an element in an array field to update without explicitly specifying the position of the element in the array. The positional operator, when used with the update() method and acts as a placeholder for the first match of the update query selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': -5, u'svm': 0}],\n",
       " u'skills': [u'python', u'SAS', u'R', u'javascript', u'java'],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample document\n",
    "posts.update({\"_id\":1234},{\"$set\":{\"skills\":[\"python\",\"SAS\",\"R\",\"javascript\",\"java\"]}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': -5, u'svm': 0}],\n",
       " u'skills': [u'python', u'SAS', u'Rstats', u'javascript', u'java'],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update R to Rstats\n",
    "posts.update({\"_id\":1234,\"skills\":\"R\"},{ \"$set\": { \"skills.$\" : \"Rstats\" }})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': -5, u'svm': 0}, {u'nb': 1, u'svm': 4}],\n",
       " u'skills': [u'python', u'SAS', u'Rstats', u'javascript', u'java'],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example\n",
    "posts.update({\"_id\":1234},{\"$push\":{\"sentiment\":{\"nb\":random.randint(-5, 5),\"svm\":random.randint(-5, 5)}}})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 1234,\n",
       " u'sentiment': [{u'nb': -5, u'svm': 0}, {u'nb': 0, u'svm': 4}],\n",
       " u'skills': [u'python', u'SAS', u'Rstats', u'javascript', u'java'],\n",
       " u'source': u'Ipython notebook',\n",
       " u'username': u'Altons'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the positional $ operator to update the value of the nb field to zero in the embedded document with the svm of 4:\n",
    "posts.update({\"_id\":1234,\"sentiment.svm\":4},{ \"$set\": { \"sentiment.$.nb\" : 0 }})\n",
    "posts.find_one({\"_id\":1234})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Data\n",
    "\n",
    "Removing databases, collections and documents in Pymongo is a straight forward process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sandpit-test', u'twitter_results', u'local']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'twitter_results', u'local']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove database sandpit-test\n",
    "conn.drop_database(\"sandpit-test\")\n",
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'system.indexes', u'dummy_collection']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a database, then a collection and a dummy document\n",
    "conn.dummy.dummy_collection.insert({\"greeting\":\"Hello World\"})\n",
    "conn.dummy.collection_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'system.indexes', u'dummy_collection']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.dummy.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'system.indexes']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete a collection\n",
    "conn.dummy.drop_collection(\"dummy_collection\")\n",
    "conn.dummy.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'twitter_results', u'local']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete dummy database\n",
    "conn.drop_database(\"dummy\")\n",
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'connectionId': 5, u'err': None, u'n': 1, u'ok': 1.0}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove documents.\n",
    "#  Please note that there is no multi=True option for remove. MongoDB will remove any documents that match the query\n",
    "posts.remove({\"_id\":5678})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't specify what documents to remove MongoDB will remove them all. This just removes the documents. The collection and its indexes still exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Commands\n",
    "\n",
    "If you need to get some statistics about your collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'avgObjSize': 400.46753246753246,\n",
       " u'collections': 3,\n",
       " u'dataSize': 61672,\n",
       " u'db': u'twitter_results',\n",
       " u'fileSize': 201326592,\n",
       " u'indexSize': 8176,\n",
       " u'indexes': 1,\n",
       " u'nsSizeMB': 16,\n",
       " u'numExtents': 4,\n",
       " u'objects': 154,\n",
       " u'ok': 1.0,\n",
       " u'storageSize': 155648}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.command({'dbstats': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get collection statistics use the collstats command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'avgObjSize': 409.76,\n",
       " u'count': 150,\n",
       " u'indexSizes': {u'_id_': 8176},\n",
       " u'lastExtentSize': 114688,\n",
       " u'nindexes': 1,\n",
       " u'ns': u'twitter_results.posts',\n",
       " u'numExtents': 2,\n",
       " u'ok': 1.0,\n",
       " u'paddingFactor': 1.0000000000000004,\n",
       " u'size': 61464,\n",
       " u'storageSize': 143360,\n",
       " u'systemFlags': 1,\n",
       " u'totalIndexSize': 8176,\n",
       " u'userFlags': 0}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.command({'collstats': 'posts'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things I did not covered in this tutorial\n",
    "\n",
    "- [Aggregation Framework](http://docs.mongodb.org/manual/reference/aggregation/) (Still chinese to me).\n",
    "- [Map Reduce](http://docs.mongodb.org/manual/applications/map-reduce/)\n",
    "- [GridFS](http://docs.mongodb.org/manual/applications/gridfs/)\n",
    "- [Journaling](http://docs.mongodb.org/manual/administration/journaling/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you find this tutorial useful. I'll be using it as my online cheat sheet! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
